{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6308b718-ac42-44c2-847a-6a1c939d48e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import re\n",
    "import warnings\n",
    "from typing import Dict, List, Union\n",
    "\n",
    "import apimoex\n",
    "import investpy\n",
    "import numpy\n",
    "import pandas\n",
    "import requests\n",
    "import yfinance\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4567d4a5-003a-488b-9576-d54ab91f28ad",
   "metadata": {},
   "source": [
    "<section style=\"font-family:system-ui,Segoe UI,Roboto,Arial,sans-serif; line-height:1.5; color:#111;\">\n",
    "  <h1 style=\"margin:0 0 8px;\">Market Risk • VaR Backtesting Mini-Project</h1>\n",
    "  <p style=\"margin:0 0 16px; color:#444;\">\n",
    "    Портфельная валидация VaR для акций, FX и долларовой облигации (UST) с рублёвой отчётностью. \n",
    "    Реализованы исторический, нормальный и модифицированный (Cornish–Fisher) VaR, а также тесты Купьице/Кристоферсена.\n",
    "  </p>\n",
    "\n",
    "  <h3 style=\"margin:16px 0 6px;\">Цель</h3>\n",
    "  <ul style=\"margin:0 0 12px 18px;\">\n",
    "    <li>Построить и сравнить <em>скользящие</em> оценки VaR на уровне 95–99% для разных классов активов.</li>\n",
    "    <li>Валидировать модели VaR тестами <strong>Kupiec UC</strong>, <strong>Christoffersen IND</strong> и <strong>Conditional Coverage</strong>.</li>\n",
    "    <li>Для UST в RUB учесть <strong>двойной риск-фактор</strong>: сдвиг доходности (duration) и движение USD/RUB.</li>\n",
    "  </ul>\n",
    "\n",
    "  <h3 style=\"margin:16px 0 6px;\">Данные и метод</h3>\n",
    "  <ul style=\"margin:0 0 12px 18px;\">\n",
    "    <li>Загрузка цен/курсов из Yahoo/Мосбиржи, нормализация колонок, базовая очистка.</li>\n",
    "    <li>Скользящее окно <code>W=250</code> для оценок квантилей и параметров распределения.</li>\n",
    "    <li>UST→RUB: линейная аппроксимация PnL: \n",
    "      <code>ΔV<sub>RUB</sub> ≈ −S·P·D<sub>mod</sub>·Δy + P·ΔS</code>.\n",
    "    </li>\n",
    "  </ul>\n",
    "\n",
    "  <h3 style=\"margin:16px 0 6px;\">Ключевые итоги</h3>\n",
    "  <ul style=\"margin:0 0 12px 18px;\">\n",
    "    <li>Исторический VaR на акциях обычно проходит UC, но проваливает IND (кластеризация хвостов).</li>\n",
    "    <li>Нормальный VaR чувствителен к «толстым хвостам» и часто проваливает UC/CC.</li>\n",
    "    <li>Модифицированный VaR устойчивее, но тоже страдает при режимных сдвигах волатильности.</li>\n",
    "    <li>В UST (в RUB) существенна FX-составляющая риска; duration-шок и FX-шок необходимо учитывать совместно.</li>\n",
    "  </ul>\n",
    "\n",
    "  <h3 style=\"margin:16px 0 6px;\">Ограничения</h3>\n",
    "  <ul style=\"margin:0 0 12px 18px;\">\n",
    "    <li>Backtest без <code>shift(1)</code> даёт look-ahead bias; для честной валидации VaR нужно смещение на один день.</li>\n",
    "    <li>В текущей версии масштабы duration/DV01 требуют правки (см. заметки в код-ревью).</li>\n",
    "    <li>Кросс-терм <code>ΔP·ΔS</code> опущен (при больших шоках может влиять).</li>\n",
    "  </ul>\n",
    "\n",
    "  <p style=\"margin:14px 0 0; color:#444;\">\n",
    "    Репозиторий демонстрирует «сквозной» пайплайн: загрузка данных → оценка VaR → рублёвая трансляция риска → backtesting.\n",
    "  </p>\n",
    "</section>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe3a198-9bc6-4a2f-800f-cc8b8b1e952c",
   "metadata": {},
   "source": [
    "## Теоретический фреймворк и формулы\n",
    "\n",
    "### VaR (однодневный)\n",
    "- **Historical VaR (левый хвост)**:  \n",
    "  $$VaR_\\alpha = -\\,q_\\alpha(r_t),$$  \n",
    "  где $r_t=\\ln(P_t/P_{t-1})$. Квантиль оценивается на скользящем окне $W$.\n",
    "\n",
    "- **Parametric Normal VaR**:  \n",
    "  $$VaR_\\alpha = -(\\mu\\,\\Delta t + z_\\alpha\\,\\sigma \\sqrt{\\Delta t}), \\quad z_\\alpha=\\Phi^{-1}(\\alpha).$$\n",
    "\n",
    "- **Modified VaR (Cornish–Fisher)**:  \n",
    "  $$\n",
    "  z_\\alpha^{CF}=z_\\alpha+\\frac{1}{6}(z_\\alpha^2-1)\\gamma\n",
    "  +\\frac{1}{24}(z_\\alpha^3-3z_\\alpha)\\kappa\n",
    "  -\\frac{1}{36}(2z_\\alpha^3-5z_\\alpha)\\gamma^2,\n",
    "  $$\n",
    "  $$\n",
    "  VaR_\\alpha=-\\big(\\mu\\,\\Delta t + z_\\alpha^{CF}\\,\\sigma\\sqrt{\\Delta t}\\big),\n",
    "  $$\n",
    "  где $\\gamma$ — асимметрия, $\\kappa$ — **excess kurtosis** на окне.\n",
    "\n",
    "---\n",
    "\n",
    "### Облигация: цена, DV01 и дюрация\n",
    "- Цена купонной облигации (nominal $N$, ставка доходности $y$, купон $c$, $m$ куп. в год):  \n",
    "  $$\n",
    "  P = \\sum_{k=1}^{mT}\\frac{N\\cdot c/m}{(1+y/m)^k}+\\frac{N}{(1+y/m)^{mT}}.\n",
    "  $$\n",
    "\n",
    "- Определения:  \n",
    "  $$\n",
    "  DV01 \\approx -\\frac{\\partial P}{\\partial y}\\cdot 0.0001,\\qquad\n",
    "  D_\\text{mod} = -\\frac{1}{P}\\frac{\\partial P}{\\partial y}=\\frac{DV01}{P\\cdot 0.0001}.\n",
    "  $$\n",
    "\n",
    "- Линейный ценовой эффект:  \n",
    "  $$\n",
    "  \\Delta P \\approx -P\\cdot D_\\text{mod}\\cdot \\Delta y = -DV01\\cdot \\frac{\\Delta y}{0.0001}.\n",
    "  $$\n",
    "\n",
    "---\n",
    "\n",
    "### UST в рублях (двухфакторная линейная аппроксимация)\n",
    "Пусть $S_t$ — USD/RUB, $P_t$ — цена облигации в USD. Тогда рублёвый PnL:\n",
    "$$\n",
    "\\boxed{\\Delta V_{RUB} \\approx -\\,S_t P_t D_\\text{mod}\\,\\Delta y_t \\;+\\; P_t\\,\\Delta S_t}\n",
    "$$\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Backtesting (UC, IND, CC)\n",
    "- **Kupiec UC**: проверяет частоту пробоев $x$ vs $p=1-\\alpha$: $LR_{uc}\\sim\\chi^2_1$.  \n",
    "- **Christoffersen IND**: проверяет независимость пробоев через матрицу переходов (00,01,10,11): $LR_{ind}\\sim\\chi^2_1$.  \n",
    "- **Conditional Coverage**: $LR_{cc}=LR_{uc}+LR_{ind}\\sim\\chi^2_2$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5eecaa88-cc99-4a25-98ca-77a4cd5376f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFactory:\n",
    "    def downloadDataFromYahooFinance(\n",
    "            self,\n",
    "            ticker: str,\n",
    "            startDate: str,\n",
    "            endDate: str,\n",
    "            autoAdjust: bool = True) -> pandas.DataFrame:\n",
    "        dataFrame = yfinance.download(ticker,\n",
    "                                      start=startDate,\n",
    "                                      end=endDate,\n",
    "                                      auto_adjust=autoAdjust,\n",
    "                                      progress=False)\n",
    "        if dataFrame.empty:\n",
    "            return dataFrame\n",
    "        dataFrame = self._flattenYahooColumns(dataFrame, [ticker])\n",
    "        return dataFrame\n",
    "\n",
    "    def downloadBondFromYahooFinance(\n",
    "            self,\n",
    "            ticker: str,\n",
    "            startDate: str,\n",
    "            endDate: str,\n",
    "            autoAdjust: bool = False) -> pandas.DataFrame:\n",
    "        dataFrame = yfinance.download(ticker,\n",
    "                                      start=startDate,\n",
    "                                      end=endDate,\n",
    "                                      auto_adjust=autoAdjust,\n",
    "                                      progress=False)\n",
    "        if dataFrame.empty:\n",
    "            return dataFrame\n",
    "        dataFrame = self._flattenYahooColumns(dataFrame, [ticker])\n",
    "        return dataFrame\n",
    "\n",
    "    def downloadFxFromYahooFinance(self, pair: str, startDate: str,\n",
    "                                   endDate: str) -> pandas.DataFrame:\n",
    "        yahooPair = self._normalizeFxTicker(pair)\n",
    "        dataFrame = yfinance.download(yahooPair,\n",
    "                                      start=startDate,\n",
    "                                      end=endDate,\n",
    "                                      auto_adjust=True,\n",
    "                                      progress=False)\n",
    "        if dataFrame.empty:\n",
    "            return dataFrame\n",
    "        dataFrame = self._flattenYahooColumns(dataFrame, [yahooPair])\n",
    "        normalizedPair = yahooPair.replace(\"=X\", \"\")\n",
    "        dataFrame.columns = [\n",
    "            column.replace(yahooPair, normalizedPair)\n",
    "            for column in dataFrame.columns\n",
    "        ]\n",
    "        return dataFrame\n",
    "\n",
    "    def downloadDataFromMoex(self, ticker: str, startDate: str,\n",
    "                             endDate: str) -> pandas.DataFrame:\n",
    "        with requests.Session() as session:\n",
    "            rawData = apimoex.get_board_history(session,\n",
    "                                                ticker,\n",
    "                                                start=startDate,\n",
    "                                                end=endDate)\n",
    "        dataFrame = pandas.DataFrame(rawData)\n",
    "        if dataFrame.empty:\n",
    "            return dataFrame\n",
    "        if 'TRADEDATE' not in dataFrame.columns:\n",
    "            return pandas.DataFrame()\n",
    "        dataFrame = dataFrame.set_index('TRADEDATE')\n",
    "        dataFrame.index = pandas.to_datetime(dataFrame.index, errors='coerce')\n",
    "        dataFrame.index.name = 'Date'\n",
    "        keepColumns = [\n",
    "            column for column in ['CLOSE', 'VOLUME', 'VALUE']\n",
    "            if column in dataFrame.columns\n",
    "        ]\n",
    "        dataFrame = dataFrame[keepColumns].copy()\n",
    "        tickerUpper = ticker.upper()\n",
    "        renameMap = {}\n",
    "        if 'CLOSE' in keepColumns:\n",
    "            renameMap['CLOSE'] = f'{tickerUpper} Close'\n",
    "        if 'VOLUME' in keepColumns:\n",
    "            renameMap['VOLUME'] = f'{tickerUpper} Volume'\n",
    "        if 'VALUE' in keepColumns:\n",
    "            renameMap['VALUE'] = f'{tickerUpper} Value'\n",
    "        dataFrame = dataFrame.rename(columns=renameMap)\n",
    "        dataFrame = dataFrame.sort_index()\n",
    "        return dataFrame\n",
    "\n",
    "    def downloadBondFromInvestingCom(self, bond: str, startDate: str,\n",
    "                                     endDate: str) -> pandas.DataFrame:\n",
    "        startDateDt = pandas.to_datetime(startDate)\n",
    "        endDateDt = pandas.to_datetime(endDate)\n",
    "        startStr = startDateDt.strftime('%d/%m/%Y')\n",
    "        endStr = endDateDt.strftime('%d/%m/%Y')\n",
    "        dataFrame = investpy.bonds.get_bond_historical_data(bond=bond,\n",
    "                                                            from_date=startStr,\n",
    "                                                            to_date=endStr)\n",
    "        if dataFrame is None or dataFrame.empty:\n",
    "            return pandas.DataFrame()\n",
    "        dataFrame.index.name = 'Date'\n",
    "        renamed = dataFrame.rename(\n",
    "            columns={\n",
    "                'Open': f'{bond} Open',\n",
    "                'High': f'{bond} High',\n",
    "                'Low': f'{bond} Low',\n",
    "                'Close': f'{bond} Close',\n",
    "                'Volume': f'{bond} Volume'\n",
    "            })\n",
    "        keep = [\n",
    "            c for c in renamed.columns\n",
    "            if c.endswith(' Close') or c.endswith(' Volume') or\n",
    "            c.endswith(' Open') or c.endswith(' High') or c.endswith(' Low')\n",
    "        ]\n",
    "        return renamed[keep].sort_index()\n",
    "\n",
    "    def downloadBondYieldFromYahooFinance(self,\n",
    "                                          code: str,\n",
    "                                          startDate: str,\n",
    "                                          endDate: str,\n",
    "                                          autoAdjust: bool = True\n",
    "                                         ) -> pandas.DataFrame:\n",
    "        mapping = {'US10Y': '^TNX', 'US30Y': '^TYX', 'US5Y': '^FVX'}\n",
    "        ticker = mapping.get(code.upper(), code)\n",
    "        dataFrame = yfinance.download(ticker,\n",
    "                                      start=startDate,\n",
    "                                      end=endDate,\n",
    "                                      auto_adjust=autoAdjust,\n",
    "                                      progress=False)\n",
    "        if dataFrame is None or dataFrame.empty:\n",
    "            return pandas.DataFrame()\n",
    "        dataFrame.index.name = 'Date'\n",
    "        dataFrame = dataFrame.rename(\n",
    "            columns={c: f'{code.upper()} {c}' for c in dataFrame.columns})\n",
    "        dataFrame = self._flattenYahooColumns(dataFrame, [ticker])\n",
    "        return dataFrame.sort_index()\n",
    "\n",
    "    def getQuotesForPortfolio(self,\n",
    "                              items: List[Union[str, Dict[str, str]]],\n",
    "                              startDate: str,\n",
    "                              endDate: str,\n",
    "                              priceField: str = 'Close',\n",
    "                              joinHow: str = 'inner') -> pandas.DataFrame:\n",
    "        collectedFrames: List[pandas.DataFrame] = []\n",
    "        for item in items:\n",
    "            meta = self._coerceItem(item)\n",
    "            ticker = meta['ticker']\n",
    "            assetClass = meta.get('assetClass') or self._inferAssetClass(ticker)\n",
    "            try:\n",
    "                if assetClass == 'fx':\n",
    "                    frame = self.downloadFxFromYahooFinance(\n",
    "                        ticker, startDate, endDate)\n",
    "                elif assetClass == 'moex':\n",
    "                    frame = self.downloadDataFromMoex(ticker, startDate,\n",
    "                                                      endDate)\n",
    "                elif assetClass == 'bond':\n",
    "                    frame = self.downloadBondFromYahooFinance(\n",
    "                        ticker, startDate, endDate)\n",
    "                elif assetClass == 'bondYield':\n",
    "                    frame = self.downloadBondYieldFromYahooFinance(\n",
    "                        ticker, startDate, endDate)\n",
    "                else:\n",
    "                    frame = self.downloadDataFromYahooFinance(\n",
    "                        ticker, startDate, endDate)\n",
    "\n",
    "                if frame is None or frame.empty:\n",
    "                    warnings.warn(\n",
    "                        f\"No data returned for {ticker} ({assetClass}). Skipping.\"\n",
    "                    )\n",
    "                    continue\n",
    "\n",
    "                targetColumns = [\n",
    "                    column for column in frame.columns\n",
    "                    if column.endswith(f' {priceField}')\n",
    "                ]\n",
    "                if not targetColumns:\n",
    "                    if priceField in frame.columns:\n",
    "                        frame = frame[[priceField]].copy()\n",
    "                        frame = frame.rename(\n",
    "                            columns={priceField: f'{ticker} {priceField}'})\n",
    "                    else:\n",
    "                        fuzzyColumns = [\n",
    "                            column for column in frame.columns\n",
    "                            if priceField.lower() in column.lower()\n",
    "                        ]\n",
    "                        if fuzzyColumns:\n",
    "                            frame = frame[[fuzzyColumns[0]]].copy()\n",
    "                        else:\n",
    "                            numericColumns = frame.select_dtypes(\n",
    "                                include=[numpy.number]).columns.tolist()\n",
    "                            if not numericColumns:\n",
    "                                warnings.warn(\n",
    "                                    f\"No numeric columns for {ticker}. Skipping.\"\n",
    "                                )\n",
    "                                continue\n",
    "                            frame = frame[[numericColumns[0]]].copy()\n",
    "                        frame.columns = [\n",
    "                            f'{self._extractTickerFromColumn(frame.columns[0])} {priceField}'\n",
    "                        ]\n",
    "                else:\n",
    "                    frame = frame[targetColumns].copy()\n",
    "\n",
    "                collectedFrames.append(frame)\n",
    "\n",
    "            except Exception as exception:\n",
    "                warnings.warn(\n",
    "                    f\"Error fetching {ticker} ({assetClass}): {exception}\")\n",
    "\n",
    "        if not collectedFrames:\n",
    "            return pandas.DataFrame()\n",
    "\n",
    "        result = pandas.concat(collectedFrames, axis=1,\n",
    "                               join=joinHow).sort_index()\n",
    "        return result\n",
    "\n",
    "    def _flattenYahooColumns(self, dataFrame: pandas.DataFrame,\n",
    "                             tickers: List[str]) -> pandas.DataFrame:\n",
    "        result = dataFrame.copy()\n",
    "        if isinstance(result.columns, pandas.MultiIndex):\n",
    "            level0Values = list(map(str, result.columns.get_level_values(0)))\n",
    "            level1Values = list(map(str, result.columns.get_level_values(1)))\n",
    "            level0Set = set(level0Values)\n",
    "            level1Set = set(level1Values)\n",
    "            tickersSet = set(map(str, tickers))\n",
    "            if tickersSet & level0Set and not (tickersSet & level1Set):\n",
    "                result.columns = [\n",
    "                    f\"{level0} {level1}\" for (level0, level1) in result.columns\n",
    "                ]\n",
    "            elif tickersSet & level1Set and not (tickersSet & level0Set):\n",
    "                result.columns = [\n",
    "                    f\"{level1} {level0}\" for (level0, level1) in result.columns\n",
    "                ]\n",
    "            else:\n",
    "                result.columns = [\n",
    "                    ' '.join(map(str, columnTuple)).strip()\n",
    "                    for columnTuple in result.columns\n",
    "                ]\n",
    "        else:\n",
    "            ticker = str(tickers[0])\n",
    "            result.columns = [f\"{ticker} {column}\" for column in result.columns]\n",
    "        result.index.name = 'Date'\n",
    "        return result\n",
    "\n",
    "    def _normalizeFxTicker(self, pair: str) -> str:\n",
    "        upperPair = pair.strip().upper()\n",
    "        if upperPair.endswith('=X'):\n",
    "            return upperPair\n",
    "        cleaned = re.sub(r'[^A-Z]', '', upperPair)\n",
    "        if len(cleaned) < 6:\n",
    "            raise ValueError(\n",
    "                f\"FX pair '{pair}' is ambiguous. Use forms like 'EURUSD' or 'EUR/USD'.\"\n",
    "            )\n",
    "        base = cleaned[:3]\n",
    "        quote = cleaned[3:6]\n",
    "        return f\"{base}{quote}=X\"\n",
    "\n",
    "    def _inferAssetClass(self, ticker: str) -> str:\n",
    "        upperTicker = ticker.strip().upper()\n",
    "        if ('=X' in upperTicker) or ('/' in upperTicker) or (re.fullmatch(\n",
    "                r'[A-Z]{6}', upperTicker) is not None):\n",
    "            return 'fx'\n",
    "        if upperTicker.endswith('.ME') or upperTicker.startswith(\n",
    "                'MOEX:') or upperTicker.endswith(':MOEX'):\n",
    "            return 'moex'\n",
    "        commonBondTickers = {\n",
    "            'TLT', 'IEF', 'BND', 'LQD', 'HYG', '^TNX', '^TYX', '^FVX', '^IRX'\n",
    "        }\n",
    "        if upperTicker in commonBondTickers:\n",
    "            return 'bond'\n",
    "        return 'stock'\n",
    "\n",
    "    def _coerceItem(self, item: Union[str, Dict[str, str]]) -> Dict[str, str]:\n",
    "        if isinstance(item, str):\n",
    "            return {'ticker': item}\n",
    "        if isinstance(item, dict) and 'ticker' in item:\n",
    "            return item\n",
    "        raise ValueError(\n",
    "            \"Each item must be a ticker string or dict with key 'ticker'.\")\n",
    "\n",
    "    def _extractTickerFromColumn(self, columnName: str) -> str:\n",
    "        parts = columnName.split()\n",
    "        if len(parts) >= 2:\n",
    "            return ' '.join(parts[:-1])\n",
    "        return parts[0]\n",
    "\n",
    "    @staticmethod\n",
    "    def makeDataframeRub(dataFrame_: pandas.DataFrame,usdRubColumnIndex:int, changeColumnsIndexes: List[int]):\n",
    "        dataFrame = dataFrame_.copy()\n",
    "        for column in changeColumnsIndexes:\n",
    "            dataFrame.iloc[:, column] = dataFrame.iloc[:, column] * dataFrame.iloc[:, usdRubColumnIndex]\n",
    "        return dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e74edf34-4333-4bc4-9afb-66050ba400ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VarCalculator:\n",
    "    def varHist(self, data, alpha=0.05):\n",
    "        return (numpy.percentile(data, alpha * 100))\n",
    "\n",
    "    def varNormal(self, data, alpha=0.05, t=1):\n",
    "        return numpy.mean(data) * t + stats.norm.ppf(alpha) * numpy.std(data) * t**.5\n",
    "\n",
    "    def varModified(self, data, alpha=0.05, t=1):\n",
    "        return numpy.mean(data) * t + self.z_corrected(data, alpha,\n",
    "                                               t) * numpy.std(data) * t**.5\n",
    "\n",
    "    @staticmethod\n",
    "    def z_corrected(data, alpha=0.05, t=1):\n",
    "        return (stats.norm.ppf(alpha) + 1 / 6 * (stats.norm.ppf(alpha)**2 - 1) *\n",
    "                (1 / t**.5) * stats.skew(data) + 1 / 24 *\n",
    "                (stats.norm.ppf(alpha)**3 - 3 * stats.norm.ppf(alpha)) *\n",
    "                (1 / t) * stats.kurtosis(data) - 1 / 36 *\n",
    "                (2 * stats.norm.ppf(alpha)**3 - 5 * stats.norm.ppf(alpha)) *\n",
    "                (1 / t) * stats.skew(data)**2)\n",
    "\n",
    "    def bondPriceFromYield(self, yieldRate, tenorYears=10.0, couponRate=None, nominal=100.0, paymentsPerYear=2):\n",
    "        if couponRate is None:\n",
    "            couponRate = yieldRate\n",
    "        numberOfPayments = int(round(paymentsPerYear * tenorYears))\n",
    "        growthPerPeriod = 1.0 + yieldRate / paymentsPerYear\n",
    "        cashCoupon = nominal * couponRate / paymentsPerYear\n",
    "        discountFactors = growthPerPeriod ** (-numpy.arange(1, numberOfPayments + 1))\n",
    "        price = cashCoupon * discountFactors.sum() + nominal * growthPerPeriod ** (-numberOfPayments)\n",
    "        return price\n",
    "\n",
    "    def dollarValueOfOneBasisPointAndModifiedDuration(self, yieldRate, tenorYears=10.0, couponRate=None, nominal=100.0, paymentsPerYear=2, bumpInBasisPoints=1.0):\n",
    "        bumpAsDecimal = bumpInBasisPoints / 10000.0\n",
    "        price = self.bondPriceFromYield(yieldRate, tenorYears, couponRate, nominal, paymentsPerYear)\n",
    "        priceUp = self.bondPriceFromYield(yieldRate + bumpAsDecimal, tenorYears, couponRate, nominal, paymentsPerYear)\n",
    "        priceDown = self.bondPriceFromYield(yieldRate - bumpAsDecimal, tenorYears, couponRate, nominal, paymentsPerYear)\n",
    "        dollarValueOfOneBasisPoint = (priceDown - priceUp) / 2.0\n",
    "        modifiedDuration = dollarValueOfOneBasisPoint / (price * 0.0001)\n",
    "        convexity = (priceUp + priceDown - 2.0 * price) / (price * bumpAsDecimal ** 2)\n",
    "        return price, dollarValueOfOneBasisPoint, modifiedDuration, convexity\n",
    "\n",
    "    def usualDurationFromModified(self, yieldRate, modifiedDuration, paymentsPerYear=2):\n",
    "        return modifiedDuration * (1.0 + yieldRate / paymentsPerYear)   \n",
    "\n",
    "    def kupiecUnconditionalCoverageLr(self, violations, confidenceLevel):\n",
    "        violations = numpy.asarray(violations, dtype=int)\n",
    "        total = violations.size\n",
    "        hits = violations.sum()\n",
    "        probability = 1.0 - confidenceLevel\n",
    "        epsilon = 1e-12\n",
    "        hitRatio = numpy.clip(hits / max(total, 1), epsilon, 1.0 - epsilon)\n",
    "        probability = numpy.clip(probability, epsilon, 1.0 - epsilon)\n",
    "        logLikelihoodUnrestricted = (total - hits) * numpy.log(1.0 - hitRatio) + hits * numpy.log(hitRatio)\n",
    "        logLikelihoodRestricted = (total - hits) * numpy.log(1.0 - probability) + hits * numpy.log(probability)\n",
    "        statistic = -2.0 * (logLikelihoodRestricted - logLikelihoodUnrestricted)\n",
    "        degreesOfFreedom = 1\n",
    "        pValue = None\n",
    "        try:\n",
    "            from scipy.stats import chi2\n",
    "            pValue = 1.0 - chi2.cdf(statistic, degreesOfFreedom)\n",
    "        except Exception:\n",
    "            pValue = None\n",
    "        return statistic, degreesOfFreedom, pValue, hits, total\n",
    "\n",
    "    def christoffersenIndependenceLr(self, violations):\n",
    "        violations = numpy.asarray(violations, dtype=int)\n",
    "        if violations.size < 2:\n",
    "            return 0.0, 1, None, 0, 0, 0, 0\n",
    "        v0 = violations[:-1]\n",
    "        v1 = violations[1:]\n",
    "        n00 = int(((v0 == 0) & (v1 == 0)).sum())\n",
    "        n01 = int(((v0 == 0) & (v1 == 1)).sum())\n",
    "        n10 = int(((v0 == 1) & (v1 == 0)).sum())\n",
    "        n11 = int(((v0 == 1) & (v1 == 1)).sum())\n",
    "        epsilon = 1e-12\n",
    "        totalZeroStarts = n00 + n01\n",
    "        totalOneStarts = n10 + n11\n",
    "        pi0 = numpy.clip(n01 / max(totalZeroStarts, 1), epsilon, 1.0 - epsilon)\n",
    "        pi1 = numpy.clip(n11 / max(totalOneStarts, 1), epsilon, 1.0 - epsilon)\n",
    "        totalTransitions = totalZeroStarts + totalOneStarts\n",
    "        pi = numpy.clip((n01 + n11) / max(totalTransitions, 1), epsilon, 1.0 - epsilon)\n",
    "        logLikelihoodRestricted = n00 * numpy.log(1.0 - pi) + n01 * numpy.log(pi) + n10 * numpy.log(1.0 - pi) + n11 * numpy.log(pi)\n",
    "        logLikelihoodUnrestricted = n00 * numpy.log(1.0 - pi0) + n01 * numpy.log(pi0) + n10 * numpy.log(1.0 - pi1) + n11 * numpy.log(pi1)\n",
    "        statistic = -2.0 * (logLikelihoodRestricted - logLikelihoodUnrestricted)\n",
    "        degreesOfFreedom = 1\n",
    "        pValue = None\n",
    "        try:\n",
    "            from scipy.stats import chi2\n",
    "            pValue = 1.0 - chi2.cdf(statistic, degreesOfFreedom)\n",
    "        except Exception:\n",
    "            pValue = None\n",
    "        return statistic, degreesOfFreedom, pValue, n00, n01, n10, n11\n",
    "\n",
    "    def christoffersenConditionalCoverageLr(self, violations, confidenceLevel):\n",
    "        statisticUnconditional, dfUnconditional, pUnconditional, hits, total = self.kupiecUnconditionalCoverageLr(\n",
    "            violations=violations, confidenceLevel=confidenceLevel\n",
    "        )\n",
    "        statisticIndependence, dfIndependence, pIndependence, n00, n01, n10, n11 = self.christoffersenIndependenceLr(\n",
    "            violations=violations\n",
    "        )\n",
    "        statistic = statisticUnconditional + statisticIndependence\n",
    "        degreesOfFreedom = dfUnconditional + dfIndependence\n",
    "        pValue = None\n",
    "        try:\n",
    "            from scipy.stats import chi2\n",
    "            pValue = 1.0 - chi2.cdf(statistic, degreesOfFreedom)\n",
    "        except Exception:\n",
    "            pValue = None\n",
    "        details = {\n",
    "            \"hits\": hits,\n",
    "            \"total\": total,\n",
    "            \"n00\": n00,\n",
    "            \"n01\": n01,\n",
    "            \"n10\": n10,\n",
    "            \"n11\": n11,\n",
    "            \"lrUnconditional\": statisticUnconditional,\n",
    "            \"lrIndependence\": statisticIndependence,\n",
    "        }\n",
    "        return statistic, degreesOfFreedom, pValue, details\n",
    "\n",
    "    def printBacktestsSummary(self, violations, confidenceLevel=0.99, significanceLevel=0.05):\n",
    "        if isinstance(violations, pandas.Series):\n",
    "            v = violations.astype(int).to_numpy()\n",
    "        else:\n",
    "            v = numpy.asarray(violations, dtype=int)\n",
    "\n",
    "        total = int(v.size)\n",
    "        hits = int(v.sum())\n",
    "        probability = 1.0 - confidenceLevel\n",
    "        expectedHits = probability * total\n",
    "\n",
    "        kupiecStat, kupiecDf, kupiecPvalue, _, _ = self.kupiecUnconditionalCoverageLr(\n",
    "            violations=v, confidenceLevel=confidenceLevel\n",
    "        )\n",
    "        indStat, indDf, indPvalue, n00, n01, n10, n11 = self.christoffersenIndependenceLr(\n",
    "            violations=v\n",
    "        )\n",
    "        combStat, combDf, combPvalue, details = self.christoffersenConditionalCoverageLr(\n",
    "            violations=v, confidenceLevel=confidenceLevel\n",
    "        )\n",
    "\n",
    "        def passFail(p):\n",
    "            return \"PASS ✅\" if (p is not None and p >= significanceLevel) else (\"FAIL ❌\" if p is not None else \"N/A\")\n",
    "\n",
    "        print(\"=== VaR Backtesting Summary ===\")\n",
    "        print(f\"Observations: {total}\")\n",
    "        print(f\"Violations: {hits}  |  Expected: {expectedHits:.2f}  (p = {probability:.4f}, confidence = {confidenceLevel:.2%})\")\n",
    "        print()\n",
    "\n",
    "        print(\"[Kupiec Unconditional Coverage]\")\n",
    "        print(f\"LR: {kupiecStat:.4f} | dof: {kupiecDf} | p-value: {('%.4f' % kupiecPvalue) if kupiecPvalue is not None else 'None'} | {passFail(kupiecPvalue)}\")\n",
    "\n",
    "        print(\"[Christoffersen Independence]\")\n",
    "        print(f\"Transitions n00={n00}, n01={n01}, n10={n10}, n11={n11}\")\n",
    "        print(f\"LR: {indStat:.4f} | dof: {indDf} | p-value: {('%.4f' % indPvalue) if indPvalue is not None else 'None'} | {passFail(indPvalue)}\")\n",
    "\n",
    "        print(\"[Conditional Coverage (Kupiec + Christoffersen)]\")\n",
    "        print(f\"LR: {combStat:.4f} | dof: {combDf} | p-value: {('%.4f' % combPvalue) if combPvalue is not None else 'None'} | {passFail(combPvalue)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f403f24-6c3c-4e3a-bb1f-ddf973d59211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL Close</th>\n",
       "      <th>USDRUB Close</th>\n",
       "      <th>SBER Close</th>\n",
       "      <th>^TNX Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>71.833313</td>\n",
       "      <td>61.694199</td>\n",
       "      <td>255.00</td>\n",
       "      <td>1.788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-06</th>\n",
       "      <td>72.405655</td>\n",
       "      <td>62.029999</td>\n",
       "      <td>253.90</td>\n",
       "      <td>1.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-08</th>\n",
       "      <td>73.224388</td>\n",
       "      <td>61.930901</td>\n",
       "      <td>259.15</td>\n",
       "      <td>1.874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-09</th>\n",
       "      <td>74.779755</td>\n",
       "      <td>61.261902</td>\n",
       "      <td>257.99</td>\n",
       "      <td>1.858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-10</th>\n",
       "      <td>74.948807</td>\n",
       "      <td>61.266102</td>\n",
       "      <td>258.19</td>\n",
       "      <td>1.825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-23</th>\n",
       "      <td>254.367035</td>\n",
       "      <td>101.842270</td>\n",
       "      <td>264.90</td>\n",
       "      <td>4.599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-24</th>\n",
       "      <td>257.286682</td>\n",
       "      <td>101.223656</td>\n",
       "      <td>264.34</td>\n",
       "      <td>4.591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-26</th>\n",
       "      <td>258.103729</td>\n",
       "      <td>99.985092</td>\n",
       "      <td>269.56</td>\n",
       "      <td>4.579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-27</th>\n",
       "      <td>254.685883</td>\n",
       "      <td>99.761086</td>\n",
       "      <td>271.20</td>\n",
       "      <td>4.619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-30</th>\n",
       "      <td>251.307877</td>\n",
       "      <td>104.518761</td>\n",
       "      <td>279.43</td>\n",
       "      <td>4.545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1202 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            AAPL Close  USDRUB Close  SBER Close  ^TNX Close\n",
       "Date                                                        \n",
       "2020-01-03   71.833313     61.694199      255.00       1.788\n",
       "2020-01-06   72.405655     62.029999      253.90       1.811\n",
       "2020-01-08   73.224388     61.930901      259.15       1.874\n",
       "2020-01-09   74.779755     61.261902      257.99       1.858\n",
       "2020-01-10   74.948807     61.266102      258.19       1.825\n",
       "...                ...           ...         ...         ...\n",
       "2024-12-23  254.367035    101.842270      264.90       4.599\n",
       "2024-12-24  257.286682    101.223656      264.34       4.591\n",
       "2024-12-26  258.103729     99.985092      269.56       4.579\n",
       "2024-12-27  254.685883     99.761086      271.20       4.619\n",
       "2024-12-30  251.307877    104.518761      279.43       4.545\n",
       "\n",
       "[1202 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factory = DataFactory()\n",
    "\n",
    "items = [\n",
    "    \"AAPL\",\n",
    "    \"USDRUB\", \n",
    "    {\"ticker\": \"SBER\", \"assetClass\": \"moex\"}, \n",
    "    {\n",
    "    'ticker': 'US10Y',\n",
    "    'assetClass': 'bondYield'\n",
    "}                \n",
    "]\n",
    "quotes = factory.getQuotesForPortfolio(items, \"2020-01-01\", \"2025-01-01\", priceField=\"Close\", joinHow=\"inner\")\n",
    "quotes = quotes.dropna()\n",
    "\n",
    "quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33fdef6e-2080-44fc-84a5-26336a6fa842",
   "metadata": {},
   "outputs": [],
   "source": [
    "quotesRub = factory.makeDataframeRub(quotes, 1, [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac720345-d85c-4077-9036-73da12e5152d",
   "metadata": {},
   "outputs": [],
   "source": [
    "varCalculator = VarCalculator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b50d65a4-ab74-4b50-8dd7-1e6dbf281c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "╔══════════════════════════════════╗\n",
      "║   BACKTEST: AAPL Close           ║\n",
      "╚══════════════════════════════════╝\n",
      "\n",
      "┌────────────────────────────┐\n",
      "│   VaR method: Historical Var │\n",
      "└────────────────────────────┘\n",
      "• Window: 250 obs | Confidence: 95% | Significance: 5%\n",
      "=== VaR Backtesting Summary ===\n",
      "Observations: 1201\n",
      "Violations: 78  |  Expected: 60.05  (p = 0.0500, confidence = 95.00%)\n",
      "\n",
      "[Kupiec Unconditional Coverage]\n",
      "LR: 5.1828 | dof: 1 | p-value: 0.0228 | FAIL ❌\n",
      "[Christoffersen Independence]\n",
      "Transitions n00=1051, n01=71, n10=71, n11=7\n",
      "LR: 0.7626 | dof: 1 | p-value: 0.3825 | PASS ✅\n",
      "[Conditional Coverage (Kupiec + Christoffersen)]\n",
      "LR: 5.9454 | dof: 2 | p-value: 0.0512 | PASS ✅\n",
      "\n",
      "┌────────────────────────┐\n",
      "│   VaR method: Normal Var │\n",
      "└────────────────────────┘\n",
      "• Window: 250 obs | Confidence: 95% | Significance: 5%\n",
      "=== VaR Backtesting Summary ===\n",
      "Observations: 1201\n",
      "Violations: 57  |  Expected: 60.05  (p = 0.0500, confidence = 95.00%)\n",
      "\n",
      "[Kupiec Unconditional Coverage]\n",
      "LR: 0.1658 | dof: 1 | p-value: 0.6839 | PASS ✅\n",
      "[Christoffersen Independence]\n",
      "Transitions n00=1091, n01=53, n10=52, n11=4\n",
      "LR: 0.6527 | dof: 1 | p-value: 0.4192 | PASS ✅\n",
      "[Conditional Coverage (Kupiec + Christoffersen)]\n",
      "LR: 0.8184 | dof: 2 | p-value: 0.6642 | PASS ✅\n",
      "\n",
      "┌──────────────────────────┐\n",
      "│   VaR method: Modified Var │\n",
      "└──────────────────────────┘\n",
      "• Window: 250 obs | Confidence: 95% | Significance: 5%\n",
      "=== VaR Backtesting Summary ===\n",
      "Observations: 1201\n",
      "Violations: 68  |  Expected: 60.05  (p = 0.0500, confidence = 95.00%)\n",
      "\n",
      "[Kupiec Unconditional Coverage]\n",
      "LR: 1.0644 | dof: 1 | p-value: 0.3022 | PASS ✅\n",
      "[Christoffersen Independence]\n",
      "Transitions n00=1067, n01=65, n10=65, n11=3\n",
      "LR: 0.2280 | dof: 1 | p-value: 0.6330 | PASS ✅\n",
      "[Conditional Coverage (Kupiec + Christoffersen)]\n",
      "LR: 1.2924 | dof: 2 | p-value: 0.5240 | PASS ✅\n",
      "\n",
      "╔════════════════════════════════════╗\n",
      "║   BACKTEST: USDRUB Close           ║\n",
      "╚════════════════════════════════════╝\n",
      "\n",
      "┌────────────────────────────┐\n",
      "│   VaR method: Historical Var │\n",
      "└────────────────────────────┘\n",
      "• Window: 250 obs | Confidence: 95% | Significance: 5%\n",
      "=== VaR Backtesting Summary ===\n",
      "Observations: 1201\n",
      "Violations: 68  |  Expected: 60.05  (p = 0.0500, confidence = 95.00%)\n",
      "\n",
      "[Kupiec Unconditional Coverage]\n",
      "LR: 1.0644 | dof: 1 | p-value: 0.3022 | PASS ✅\n",
      "[Christoffersen Independence]\n",
      "Transitions n00=1070, n01=62, n10=62, n11=6\n",
      "LR: 1.1701 | dof: 1 | p-value: 0.2794 | PASS ✅\n",
      "[Conditional Coverage (Kupiec + Christoffersen)]\n",
      "LR: 2.2346 | dof: 2 | p-value: 0.3272 | PASS ✅\n",
      "\n",
      "┌────────────────────────┐\n",
      "│   VaR method: Normal Var │\n",
      "└────────────────────────┘\n",
      "• Window: 250 obs | Confidence: 95% | Significance: 5%\n",
      "=== VaR Backtesting Summary ===\n",
      "Observations: 1201\n",
      "Violations: 49  |  Expected: 60.05  (p = 0.0500, confidence = 95.00%)\n",
      "\n",
      "[Kupiec Unconditional Coverage]\n",
      "LR: 2.2777 | dof: 1 | p-value: 0.1312 | PASS ✅\n",
      "[Christoffersen Independence]\n",
      "Transitions n00=1103, n01=48, n10=48, n11=1\n",
      "LR: 0.6578 | dof: 1 | p-value: 0.4173 | PASS ✅\n",
      "[Conditional Coverage (Kupiec + Christoffersen)]\n",
      "LR: 2.9354 | dof: 2 | p-value: 0.2305 | PASS ✅\n",
      "\n",
      "┌──────────────────────────┐\n",
      "│   VaR method: Modified Var │\n",
      "└──────────────────────────┘\n",
      "• Window: 250 obs | Confidence: 95% | Significance: 5%\n",
      "=== VaR Backtesting Summary ===\n",
      "Observations: 1201\n",
      "Violations: 61  |  Expected: 60.05  (p = 0.0500, confidence = 95.00%)\n",
      "\n",
      "[Kupiec Unconditional Coverage]\n",
      "LR: 0.0157 | dof: 1 | p-value: 0.9002 | PASS ✅\n",
      "[Christoffersen Independence]\n",
      "Transitions n00=1085, n01=54, n10=54, n11=7\n",
      "LR: 4.1524 | dof: 1 | p-value: 0.0416 | FAIL ❌\n",
      "[Conditional Coverage (Kupiec + Christoffersen)]\n",
      "LR: 4.1682 | dof: 2 | p-value: 0.1244 | PASS ✅\n",
      "\n",
      "╔══════════════════════════════════╗\n",
      "║   BACKTEST: SBER Close           ║\n",
      "╚══════════════════════════════════╝\n",
      "\n",
      "┌────────────────────────────┐\n",
      "│   VaR method: Historical Var │\n",
      "└────────────────────────────┘\n",
      "• Window: 250 obs | Confidence: 95% | Significance: 5%\n",
      "=== VaR Backtesting Summary ===\n",
      "Observations: 1201\n",
      "Violations: 79  |  Expected: 60.05  (p = 0.0500, confidence = 95.00%)\n",
      "\n",
      "[Kupiec Unconditional Coverage]\n",
      "LR: 5.7512 | dof: 1 | p-value: 0.0165 | FAIL ❌\n",
      "[Christoffersen Independence]\n",
      "Transitions n00=1050, n01=71, n10=71, n11=8\n",
      "LR: 1.5142 | dof: 1 | p-value: 0.2185 | PASS ✅\n",
      "[Conditional Coverage (Kupiec + Christoffersen)]\n",
      "LR: 7.2654 | dof: 2 | p-value: 0.0264 | FAIL ❌\n",
      "\n",
      "┌────────────────────────┐\n",
      "│   VaR method: Normal Var │\n",
      "└────────────────────────┘\n",
      "• Window: 250 obs | Confidence: 95% | Significance: 5%\n",
      "=== VaR Backtesting Summary ===\n",
      "Observations: 1201\n",
      "Violations: 54  |  Expected: 60.05  (p = 0.0500, confidence = 95.00%)\n",
      "\n",
      "[Kupiec Unconditional Coverage]\n",
      "LR: 0.6631 | dof: 1 | p-value: 0.4155 | PASS ✅\n",
      "[Christoffersen Independence]\n",
      "Transitions n00=1097, n01=49, n10=49, n11=5\n",
      "LR: 2.3420 | dof: 1 | p-value: 0.1259 | PASS ✅\n",
      "[Conditional Coverage (Kupiec + Christoffersen)]\n",
      "LR: 3.0051 | dof: 2 | p-value: 0.2226 | PASS ✅\n",
      "\n",
      "┌──────────────────────────┐\n",
      "│   VaR method: Modified Var │\n",
      "└──────────────────────────┘\n",
      "• Window: 250 obs | Confidence: 95% | Significance: 5%\n",
      "=== VaR Backtesting Summary ===\n",
      "Observations: 1201\n",
      "Violations: 67  |  Expected: 60.05  (p = 0.0500, confidence = 95.00%)\n",
      "\n",
      "[Kupiec Unconditional Coverage]\n",
      "LR: 0.8174 | dof: 1 | p-value: 0.3659 | PASS ✅\n",
      "[Christoffersen Independence]\n",
      "Transitions n00=1074, n01=59, n10=59, n11=8\n",
      "LR: 4.2476 | dof: 1 | p-value: 0.0393 | FAIL ❌\n",
      "[Conditional Coverage (Kupiec + Christoffersen)]\n",
      "LR: 5.0650 | dof: 2 | p-value: 0.0795 | PASS ✅\n",
      "\n",
      "╔══════════════════════════════════╗\n",
      "║   BACKTEST: ^TNX Close           ║\n",
      "╚══════════════════════════════════╝\n",
      "\n",
      "┌────────────────────────────┐\n",
      "│   VaR method: Historical Var │\n",
      "└────────────────────────────┘\n",
      "• Window: 250 obs | Confidence: 95% | Significance: 5%\n",
      "=== VaR Backtesting Summary ===\n",
      "Observations: 1171\n",
      "Violations: 71  |  Expected: 58.55  (p = 0.0500, confidence = 95.00%)\n",
      "\n",
      "[Kupiec Unconditional Coverage]\n",
      "LR: 2.6173 | dof: 1 | p-value: 0.1057 | PASS ✅\n",
      "[Christoffersen Independence]\n",
      "Transitions n00=1035, n01=64, n10=64, n11=7\n",
      "LR: 1.6387 | dof: 1 | p-value: 0.2005 | PASS ✅\n",
      "[Conditional Coverage (Kupiec + Christoffersen)]\n",
      "LR: 4.2559 | dof: 2 | p-value: 0.1191 | PASS ✅\n",
      "\n",
      "┌────────────────────────┐\n",
      "│   VaR method: Normal Var │\n",
      "└────────────────────────┘\n",
      "• Window: 250 obs | Confidence: 95% | Significance: 5%\n",
      "=== VaR Backtesting Summary ===\n",
      "Observations: 1171\n",
      "Violations: 50  |  Expected: 58.55  (p = 0.0500, confidence = 95.00%)\n",
      "\n",
      "[Kupiec Unconditional Coverage]\n",
      "LR: 1.3797 | dof: 1 | p-value: 0.2401 | PASS ✅\n",
      "[Christoffersen Independence]\n",
      "Transitions n00=1071, n01=49, n10=49, n11=1\n",
      "LR: 0.8097 | dof: 1 | p-value: 0.3682 | PASS ✅\n",
      "[Conditional Coverage (Kupiec + Christoffersen)]\n",
      "LR: 2.1894 | dof: 2 | p-value: 0.3346 | PASS ✅\n",
      "\n",
      "┌──────────────────────────┐\n",
      "│   VaR method: Modified Var │\n",
      "└──────────────────────────┘\n",
      "• Window: 250 obs | Confidence: 95% | Significance: 5%\n",
      "=== VaR Backtesting Summary ===\n",
      "Observations: 1171\n",
      "Violations: 60  |  Expected: 58.55  (p = 0.0500, confidence = 95.00%)\n",
      "\n",
      "[Kupiec Unconditional Coverage]\n",
      "LR: 0.0375 | dof: 1 | p-value: 0.8464 | PASS ✅\n",
      "[Christoffersen Independence]\n",
      "Transitions n00=1057, n01=53, n10=53, n11=7\n",
      "LR: 4.2298 | dof: 1 | p-value: 0.0397 | FAIL ❌\n",
      "[Conditional Coverage (Kupiec + Christoffersen)]\n",
      "LR: 4.2673 | dof: 2 | p-value: 0.1184 | PASS ✅\n"
     ]
    }
   ],
   "source": [
    "def printAssetHeader(assetName: str):\n",
    "    line = \"═\" * max(20, len(assetName) + 24)\n",
    "    print(f\"\\n╔{line}╗\")\n",
    "    print(f\"║   BACKTEST: {assetName} \".ljust(len(line) + 1) + \"║\")\n",
    "    print(f\"╚{line}╝\")\n",
    "\n",
    "def printVarTestHeader(testName: str):\n",
    "    line = \"─\" * max(12, len(testName) + 14)\n",
    "    print(f\"\\n┌{line}┐\")\n",
    "    print(f\"│   VaR method: {testName} \".ljust(len(line) + 1) + \"│\")\n",
    "    print(f\"└{line}┘\")\n",
    "\n",
    "# Карта имён серий с VaR\n",
    "varTests = [\n",
    "    \"Historical Var\",\n",
    "    \"Normal Var\",\n",
    "    \"Modified Var\"\n",
    "]\n",
    "mapVarTest = {\n",
    "    \"Historical Var\": \"VarHist\",\n",
    "    \"Normal Var\": \"VarNormal\",\n",
    "    \"Modified Var\": \"VarModified\"\n",
    "}\n",
    "\n",
    "# Основной цикл по активам/колонкам\n",
    "for columnId in range(len(quotes.columns)):\n",
    "    assetName = str(quotes.columns[columnId])\n",
    "    printAssetHeader(assetName)\n",
    "\n",
    "    # Подготовка данных\n",
    "    observedSeries = quotes.iloc[:, columnId].to_frame(name=\"price\")\n",
    "    observedSeries[\"return\"] = numpy.log(observedSeries[\"price\"] / observedSeries[\"price\"].shift(1))\n",
    "    observedSeries = observedSeries.dropna()\n",
    "\n",
    "    # Расчёт VaR\n",
    "    if columnId in (0, 2):\n",
    "        # Акции (VaR в относительных величинах доходности)\n",
    "        observedSeries[\"VarHist\"] = observedSeries[\"return\"].rolling(window=30).apply(varCalculator.varHist, raw=True)\n",
    "        observedSeries[\"VarNormal\"] = observedSeries[\"return\"].rolling(window=30).apply(varCalculator.varNormal, raw=True)\n",
    "        observedSeries[\"VarModified\"] = observedSeries[\"return\"].rolling(window=30).apply(varCalculator.varModified, raw=True)\n",
    "    elif columnId == 1:\n",
    "        # FX (преобразуем относительный VaR в денежный VaR на текущую цену)\n",
    "        observedSeries[\"VarHist\"] = observedSeries[\"return\"].rolling(window=30).apply(varCalculator.varHist, raw=True) * observedSeries[\"price\"]\n",
    "        observedSeries[\"VarNormal\"] = observedSeries[\"return\"].rolling(window=30).apply(varCalculator.varNormal, raw=True) * observedSeries[\"price\"]\n",
    "        observedSeries[\"VarModified\"] = observedSeries[\"return\"].rolling(window=30).apply(varCalculator.varModified, raw=True) * observedSeries[\"price\"]\n",
    "    elif columnId == 3:\n",
    "        observedSeries[\"yieldDecimal\"] = observedSeries[\"price\"] / 100.0\n",
    "        observedSeries[\"deltaYield\"]   = observedSeries[\"yieldDecimal\"].diff()\n",
    "    \n",
    "        fxSeries = quotes.iloc[:, 1].to_frame(name=\"fxPrice\") \n",
    "        observedSeries = observedSeries.join(fxSeries, how=\"inner\")\n",
    "        observedSeries[\"deltaFx\"] = observedSeries[\"fxPrice\"].diff()\n",
    "    \n",
    "        priceList = []\n",
    "        dmodList  = []\n",
    "        for y in observedSeries[\"yieldDecimal\"]:\n",
    "            if numpy.isnan(y):\n",
    "                priceList.append(numpy.nan)\n",
    "                dmodList.append(numpy.nan)\n",
    "            else:\n",
    "                price_t, dv01_t, dmod_t, _ = varCalculator.dollarValueOfOneBasisPointAndModifiedDuration(\n",
    "                    yieldRate=y,\n",
    "                    tenorYears=10.0,\n",
    "                    couponRate=None,\n",
    "                    nominal=100.0,\n",
    "                    paymentsPerYear=2,\n",
    "                    bumpInBasisPoints=1.0\n",
    "                )\n",
    "                priceList.append(price_t)\n",
    "                dmodList.append(dmod_t)\n",
    "    \n",
    "        observedSeries[\"bondPriceParLike\"] = numpy.array(priceList)      # P_t in USD per 100 nominal\n",
    "        observedSeries[\"modifiedDuration\"] = numpy.array(dmodList)       # D_mod in years\n",
    "    \n",
    "        observedSeries[\"rubLossRates\"] = - observedSeries[\"fxPrice\"] * observedSeries[\"bondPriceParLike\"] * observedSeries[\"modifiedDuration\"] * observedSeries[\"deltaYield\"]\n",
    "        observedSeries[\"rubLossFx\"]    =   observedSeries[\"bondPriceParLike\"] * observedSeries[\"deltaFx\"]\n",
    "    \n",
    "        observedSeries[\"rubLossTotal\"] = observedSeries[\"rubLossRates\"] + observedSeries[\"rubLossFx\"]\n",
    "    \n",
    "        observedSeries[\"VarHist\"]     = observedSeries[\"rubLossTotal\"].rolling(window=30).apply(varCalculator.varHist,     raw=True)\n",
    "        observedSeries[\"VarNormal\"]   = observedSeries[\"rubLossTotal\"].rolling(window=30).apply(varCalculator.varNormal,   raw=True)\n",
    "        observedSeries[\"VarModified\"] = observedSeries[\"rubLossTotal\"].rolling(window=30).apply(varCalculator.varModified, raw=True)\n",
    "    \n",
    "        observedSeries = observedSeries.dropna(subset=[\"VarHist\",\"VarNormal\",\"VarModified\",\"rubLossTotal\"])\n",
    "            \n",
    "\n",
    "    for testId in range(3):\n",
    "        testVarName = varTests[testId]\n",
    "        varColumn = mapVarTest[testVarName]\n",
    "        printVarTestHeader(testVarName)\n",
    "\n",
    "        if columnId in (0, 2):\n",
    "            violations = observedSeries[\"return\"] < observedSeries[varColumn]\n",
    "        elif columnId == 1:\n",
    "            moneyLoss = observedSeries[\"return\"] * observedSeries[\"price\"]\n",
    "            violations = moneyLoss < observedSeries[varColumn]\n",
    "        elif columnId == 3:\n",
    "            violations = observedSeries[\"rubLossTotal\"] < observedSeries[varColumn]\n",
    "\n",
    "        print(f\"• Window: 250 obs | Confidence: 95% | Significance: 5%\")\n",
    "        varCalculator.printBacktestsSummary(\n",
    "            violations=violations,\n",
    "            confidenceLevel=0.95,\n",
    "            significanceLevel=0.05\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde4a109-ff16-44a8-9661-694dcaf05595",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede6ce76-8ef9-4e1e-853e-3dac0cb1c747",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
